{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"HnTm7M72ZiwX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702364984174,"user_tz":480,"elapsed":25135,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"426b1833-95ad-4f40-9117-a00adb84bd80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Installing collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","Successfully installed scikit-learn-1.3.2\n"]}],"source":["'''\n","Question Answering (QA) System using NLP with SQuAD\n","EE562 Group3 Project\n","Megha Chandra Nandyala\n","Amisha Himanshu Somaiya\n","\n","\n","APPROACH       : Traditional Machine Learning Approaches\n","                 - Multinomial Logistic Regression\n","                 - Random Forest\n","\n","PRE-PROCESSING :\n","Using NLTK-Punkt, Textblob, InferSent and GLoVE\n","Before giving the inputs to the model, the data needs to be pre-processed.\n","First, we convert the passage to blobs of paragraphs using an instance of textblob library.\n","Paragraphs are then split to sentences and a maximum length is pre-determined based on model capability.\n","If the sentence length is more than this, it is truncated and if it is less, the sentence is padded with special padding tokens.\n","The sentences are then split to words and tokenized. We are using the Punkt tokenizer from NLTK.\n","Then a vocabulary of words is generated using glove model from Facebook that uses GLOVE word to vector embeddings.\n","Then, separate embeddings are generated for the passage and for the questions.\n","Embeddings are vectors that group words with similar context together based on their similarity score.\n","For eg, apple and banana will have the same grouping but apple and car will not.\n","\n","HAND-CRAFTED FEATURES :\n","Generate features of Euclidean Distance and Cosine Similarity and append to the dataframe\n","\n","FIT and PREDICT :\n","Use the resultant dataframes with context, question, sentence embeddings, question embeddings, and hand-crafted features to fit and predict on 2 classifiers :\n","multinomial logistic regression and random forest.\n","\n","METRICS :\n","Evaluate using F1 and EM scores.\n","\n","REFERENCES :\n","https://arxiv.org/abs/1705.02364\n","https://github.com/facebookresearch/InferSent\n","https://nlp.stanford.edu/projects/glove/\n","https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n","https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n","https://www.v7labs.com/blog/f1-score-guide\n","https://huggingface.co/spaces/evaluate-metric/exact_match\n","\n","'''\n","\n","\n","\n","!pip install -U scikit-learn\n"]},{"cell_type":"code","source":["# import libraries\n","import pandas as pd\n","import numpy as np\n","import pickle\n","from textblob import TextBlob\n","import torch\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn import linear_model\n","from sklearn import metrics\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","import numpy as np\n","from numpy import dot\n","from numpy.linalg import norm\n","import joblib\n","\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"HWW9mp-saLwr","executionInfo":{"status":"ok","timestamp":1702365051343,"user_tz":480,"elapsed":7810,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXsdL_LUaMCU","executionInfo":{"status":"ok","timestamp":1702365081399,"user_tz":480,"elapsed":17627,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"cf2c3563-51d1-414a-8c76-2ca0aeb770c4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","# sys.path.append('/content/drive/MyDrive/qa-nlp/')  #megha\n","sys.path.append('/content/drive/MyDrive/EE562_Group3_Project/multinomial_and_randomforest/')    #amisha"],"metadata":{"id":"UrdAve0maDLG","executionInfo":{"status":"ok","timestamp":1702365472352,"user_tz":480,"elapsed":297,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"gmu5qL4VZiwa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702365172669,"user_tz":480,"elapsed":828,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"74dadbaf-f2ab-4f95-9137-aeb86d41db00"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["# Use the Punkt unsupervised tokenizer from the NLTK (Natural Language ToolKit) library\n","import nltk\n","nltk.download('punkt')"]},{"cell_type":"code","source":["# Use Infersent model from Facebook to create vocabulary and separate embeddings for question and for context\n","# Infersent uses GLoVE pre-trained word to vector embeddings\n","# Referred https://github.com/facebookresearch/InferSent\n","from models import InferSent\n","\n","# megha\n","# V = 1\n","# MODEL_PATH = '/content/drive/MyDrive/qa-nlp/encoder/infersent%s.pkl' % V\n","# params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n","#                 'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n","# infersent = InferSent(params_model)\n","# infersent.load_state_dict(torch.load(MODEL_PATH))\n","# W2V_PATH = '/content/drive/MyDrive/qa-nlp/GloVe/glove.840B.300d.txt'\n","# infersent.set_w2v_path(W2V_PATH)\n","\n","\n","# amisha\n","V = 1\n","MODEL_PATH = '/content/drive/MyDrive/EE562_Group3_Project/multinomial_and_randomforest/encoder/infersent%s.pkl' % V\n","params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n","                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n","infersent = InferSent(params_model)\n","infersent.load_state_dict(torch.load(MODEL_PATH))\n","W2V_PATH = '/content/drive/MyDrive/EE562_Group3_Project/multinomial_and_randomforest/GloVe/glove.840B.300d.txt'\n","infersent.set_w2v_path(W2V_PATH)"],"metadata":{"id":"zKmxXhrI3P0n","executionInfo":{"status":"ok","timestamp":1702365580846,"user_tz":480,"elapsed":2152,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# read training data\n","\n","# megha\n","# train = pd.read_json('/content/drive/MyDrive/qa-nlp/data/train-v1.1.json')\n","\n","# amisha\n","train = pd.read_json('/content/drive/MyDrive/EE562_Group3_Project/multinomial_and_randomforest/data/train-v1.1.json')"],"metadata":{"id":"wtnq--c36WfR","executionInfo":{"status":"ok","timestamp":1702365914690,"user_tz":480,"elapsed":2237,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Ze96ajxDZiwd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702367408051,"user_tz":480,"elapsed":201,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"acc6c87e-0f95-41e6-ffc1-05ca0e7c17c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 4)"]},"metadata":{},"execution_count":25}],"source":["# create dataframes and add to them the extracted individual attributes of data\n","contexts, questions, answers, titles = [], [], [], [] #initializations\n","\n","def get_attributes(item):  #extract and create separate lists\n","    data = item['data']\n","    title = data['title']\n","    for paragraph in data['paragraphs']:\n","        for qas in paragraph['qas']:\n","            answers.append(qas['answers'][0]['text'])\n","            questions.append(qas['question'])\n","            contexts.append(paragraph['context'])\n","            titles.append(title)\n","\n","\n","\n","def build_dataframe(train):   #create dataframe, later add handcrafted features to this dataframe\n","    train.apply(get_attributes, axis = 1)\n","    train_df = pd.DataFrame({\n","    'contexts':contexts,\n","    'questions': questions,\n","    'answers': answers,\n","    'titles': titles\n","})\n","    return train_df\n","\n","train_df = build_dataframe(train)\n","train_df = train_df.head(5000)\n","train_df.shape"]},{"cell_type":"code","source":["# The blobs i.e. paragraphs are further split into sentences for processing\n","train_df['sentences'] = train_df['contexts'].apply(lambda x : [item.raw for item in TextBlob(x).sentences ])"],"metadata":{"id":"T1kt5hLX7Urc","executionInfo":{"status":"ok","timestamp":1702367413080,"user_tz":480,"elapsed":2188,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"id":"zacRfd19Ziwf","executionInfo":{"status":"ok","timestamp":1702367513915,"user_tz":480,"elapsed":217,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["# custom function to get the answer from sentences\n","def get_target(item):\n","    '''\n","    Builds the target using the index number of answer in the list of sentences\n","    '''\n","    for index, sentence in enumerate( item['sentences']):\n","        if item['answers'] in sentence:\n","            return index\n","    return 0\n","\n","train_df['target'] = train_df.apply(get_target, axis = 1)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"Nv_n-NLRZiwf","executionInfo":{"status":"ok","timestamp":1702367546411,"user_tz":480,"elapsed":202,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["# custom function to get all sentences together in a list\n","def get_all_sentences(sentences):\n","    all_sentences = []\n","    sentences = sentences.tolist()\n","    for context_sentences in sentences:\n","        for setence in context_sentences:\n","            all_sentences.append(setence)\n","\n","    all_sentences = list(dict.fromkeys(all_sentences))\n","    return all_sentences"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXPEmHokZiwg","executionInfo":{"status":"ok","timestamp":1702367693545,"user_tz":480,"elapsed":90343,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"cc06ba15-7c20-486f-9201-5cbb3f6f93e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 14622(/15388) words with w2v vectors\n","Vocab size : 14622\n"]}],"source":["# Generate vocabulary using InferSent which uses GLoVE inherently\n","paras = list(train_df[\"contexts\"].drop_duplicates().reset_index(drop= True))\n","blob = TextBlob(\" \".join(paras))\n","sentences = get_all_sentences(train_df['sentences'])\n","infersent.build_vocab(sentences, tokenize=True)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"rZIcBy8kZiwg","executionInfo":{"status":"ok","timestamp":1702370167380,"user_tz":480,"elapsed":2470723,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["#generate separate embeddings for context (i.e. sentences) and for the questions\n","#sentence Embeddings\n","dict_embeddings = {}\n","for i in range(len(sentences)):\n","    dict_embeddings[sentences[i]] = infersent.encode([sentences[i]], tokenize=True)[0]\n","\n","#question Embeddings\n","questions = list(train_df[\"questions\"])\n","for i in range(len(questions)):\n","    dict_embeddings[questions[i]] = infersent.encode([questions[i]], tokenize=True)[0]\n"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"wYmVC_iHZiwh","executionInfo":{"status":"ok","timestamp":1702370188413,"user_tz":480,"elapsed":180,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["#method definition to save all embeddings for sentences in a list embeddings\n","def get_context_embeddings(item):\n","    embeddings = []\n","    for sentence in item.sentences:\n","        embeddings.append(dict_embeddings[sentence])\n","    return embeddings"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"SZuX3YQ4Ziwh","executionInfo":{"status":"ok","timestamp":1702370190874,"user_tz":480,"elapsed":248,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["#add these embeddings to the dataframe\n","train_df['question_embedding'] = train_df['questions'].apply(lambda x : dict_embeddings[x])\n","train_df['context_embedding'] = train_df.apply(get_context_embeddings, axis = 1)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"OZodKZWPZiwi","executionInfo":{"status":"ok","timestamp":1702370192291,"user_tz":480,"elapsed":161,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["# generate hand-crafted features using Euclidean Distance and Cosine Similarity Score\n","from sklearn.metrics.pairwise import euclidean_distances"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"L_nM_IqFZiwi","executionInfo":{"status":"ok","timestamp":1702370193911,"user_tz":480,"elapsed":165,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["# calculate the metrics\n","def get_metric(item, metric):\n","    result = []\n","    for i in range(0,len(item.sentences)):\n","        question_embedding = [item.question_embedding]\n","        sentence_embedding = [item['context_embedding'][i]]\n","\n","        if metric == 'cosine_similarity':\n","            metric = cosine_similarity(question_embedding, sentence_embedding)\n","\n","        if metric == 'euclidean':\n","            metric = euclidean_distances(question_embedding, sentence_embedding)\n","\n","        result.append(metric[0][0])\n","    return result\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"rvk-VxszZiwi","executionInfo":{"status":"ok","timestamp":1702370205059,"user_tz":480,"elapsed":8598,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["# add the hand-crafted features to the dataframes\n","train_df['cosine_similarity'] = train_df.apply(lambda item : get_metric(item, 'cosine_similarity'), axis = 1)\n","train_df['euclidean'] = train_df.apply(lambda item : get_metric(item, 'euclidean'), axis = 1)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"IhOkUhQHZiwi","executionInfo":{"status":"ok","timestamp":1702370210178,"user_tz":480,"elapsed":235,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"779d8bfe-d7ab-4921-b7e5-1bcaab3c34db"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            contexts  \\\n","0  Architecturally, the school has a Catholic cha...   \n","1  Architecturally, the school has a Catholic cha...   \n","2  Architecturally, the school has a Catholic cha...   \n","3  Architecturally, the school has a Catholic cha...   \n","4  Architecturally, the school has a Catholic cha...   \n","\n","                                           questions  \\\n","0  To whom did the Virgin Mary allegedly appear i...   \n","1  What is in front of the Notre Dame Main Building?   \n","2  The Basilica of the Sacred heart at Notre Dame...   \n","3                  What is the Grotto at Notre Dame?   \n","4  What sits on top of the Main Building at Notre...   \n","\n","                                   answers                    titles  \\\n","0               Saint Bernadette Soubirous  University_of_Notre_Dame   \n","1                a copper statue of Christ  University_of_Notre_Dame   \n","2                        the Main Building  University_of_Notre_Dame   \n","3  a Marian place of prayer and reflection  University_of_Notre_Dame   \n","4       a golden statue of the Virgin Mary  University_of_Notre_Dame   \n","\n","                                           sentences  target  \\\n","0  [Architecturally, the school has a Catholic ch...       5   \n","1  [Architecturally, the school has a Catholic ch...       2   \n","2  [Architecturally, the school has a Catholic ch...       1   \n","3  [Architecturally, the school has a Catholic ch...       4   \n","4  [Architecturally, the school has a Catholic ch...       1   \n","\n","                                  question_embedding  \\\n","0  [0.1101008, 0.1142294, 0.11560897, 0.054894753...   \n","1  [0.10951651, 0.11030623, 0.05210006, 0.0305399...   \n","2  [0.011956469, 0.14930709, 0.028481215, 0.05278...   \n","3  [0.0711433, 0.054118324, -0.013959841, 0.05310...   \n","4  [0.16131133, 0.15654244, 0.08214858, 0.0437286...   \n","\n","                                   context_embedding  \\\n","0  [[0.055199962, 0.05013141, 0.047870383, 0.0162...   \n","1  [[0.055199962, 0.05013141, 0.047870383, 0.0162...   \n","2  [[0.055199962, 0.05013141, 0.047870383, 0.0162...   \n","3  [[0.055199962, 0.05013141, 0.047870383, 0.0162...   \n","4  [[0.055199962, 0.05013141, 0.047870383, 0.0162...   \n","\n","                                   cosine_similarity  \\\n","0  [0.5752636, 0.5752636, 0.5752636, 0.5752636, 0...   \n","1  [0.5459254, 0.5459254, 0.5459254, 0.5459254, 0...   \n","2  [0.6082523, 0.6082523, 0.6082523, 0.6082523, 0...   \n","3  [0.50993013, 0.50993013, 0.50993013, 0.5099301...   \n","4  [0.52223635, 0.52223635, 0.52223635, 0.5222363...   \n","\n","                                           euclidean  \n","0  [3.8162625, 3.8162625, 3.8162625, 3.8162625, 3...  \n","1  [3.590196, 3.590196, 3.590196, 3.590196, 3.590...  \n","2  [3.4122276, 3.4122276, 3.4122276, 3.4122276, 3...  \n","3  [3.6493201, 3.6493201, 3.6493201, 3.6493201, 3...  \n","4  [3.7629066, 3.7629066, 3.7629066, 3.7629066, 3...  "],"text/html":["\n","  <div id=\"df-6ec5fbc8-44f0-49cf-b70c-67769a8f12e2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>contexts</th>\n","      <th>questions</th>\n","      <th>answers</th>\n","      <th>titles</th>\n","      <th>sentences</th>\n","      <th>target</th>\n","      <th>question_embedding</th>\n","      <th>context_embedding</th>\n","      <th>cosine_similarity</th>\n","      <th>euclidean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>To whom did the Virgin Mary allegedly appear i...</td>\n","      <td>Saint Bernadette Soubirous</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>[Architecturally, the school has a Catholic ch...</td>\n","      <td>5</td>\n","      <td>[0.1101008, 0.1142294, 0.11560897, 0.054894753...</td>\n","      <td>[[0.055199962, 0.05013141, 0.047870383, 0.0162...</td>\n","      <td>[0.5752636, 0.5752636, 0.5752636, 0.5752636, 0...</td>\n","      <td>[3.8162625, 3.8162625, 3.8162625, 3.8162625, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is in front of the Notre Dame Main Building?</td>\n","      <td>a copper statue of Christ</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>[Architecturally, the school has a Catholic ch...</td>\n","      <td>2</td>\n","      <td>[0.10951651, 0.11030623, 0.05210006, 0.0305399...</td>\n","      <td>[[0.055199962, 0.05013141, 0.047870383, 0.0162...</td>\n","      <td>[0.5459254, 0.5459254, 0.5459254, 0.5459254, 0...</td>\n","      <td>[3.590196, 3.590196, 3.590196, 3.590196, 3.590...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n","      <td>the Main Building</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>[Architecturally, the school has a Catholic ch...</td>\n","      <td>1</td>\n","      <td>[0.011956469, 0.14930709, 0.028481215, 0.05278...</td>\n","      <td>[[0.055199962, 0.05013141, 0.047870383, 0.0162...</td>\n","      <td>[0.6082523, 0.6082523, 0.6082523, 0.6082523, 0...</td>\n","      <td>[3.4122276, 3.4122276, 3.4122276, 3.4122276, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is the Grotto at Notre Dame?</td>\n","      <td>a Marian place of prayer and reflection</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>[Architecturally, the school has a Catholic ch...</td>\n","      <td>4</td>\n","      <td>[0.0711433, 0.054118324, -0.013959841, 0.05310...</td>\n","      <td>[[0.055199962, 0.05013141, 0.047870383, 0.0162...</td>\n","      <td>[0.50993013, 0.50993013, 0.50993013, 0.5099301...</td>\n","      <td>[3.6493201, 3.6493201, 3.6493201, 3.6493201, 3...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What sits on top of the Main Building at Notre...</td>\n","      <td>a golden statue of the Virgin Mary</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>[Architecturally, the school has a Catholic ch...</td>\n","      <td>1</td>\n","      <td>[0.16131133, 0.15654244, 0.08214858, 0.0437286...</td>\n","      <td>[[0.055199962, 0.05013141, 0.047870383, 0.0162...</td>\n","      <td>[0.52223635, 0.52223635, 0.52223635, 0.5222363...</td>\n","      <td>[3.7629066, 3.7629066, 3.7629066, 3.7629066, 3...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ec5fbc8-44f0-49cf-b70c-67769a8f12e2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6ec5fbc8-44f0-49cf-b70c-67769a8f12e2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6ec5fbc8-44f0-49cf-b70c-67769a8f12e2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1f2a74ab-8e81-4959-a79c-04bb8416e9c2\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f2a74ab-8e81-4959-a79c-04bb8416e9c2')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1f2a74ab-8e81-4959-a79c-04bb8416e9c2 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":36}],"source":["train_df.head()"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"fmEyW3hCZiwj","executionInfo":{"status":"ok","timestamp":1702370213186,"user_tz":480,"elapsed":253,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["train_df_copy = train_df.copy()"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"0ZsE5rNuZiwj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702370215416,"user_tz":480,"elapsed":972,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"3483415c-e751-4fde-cf85-93e3a54d6e55"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{},"execution_count":38}],"source":["# function to find maximum number of sentences in any context\n","def find_max_number_of_sentences():\n","    max_number_of_sentences = 0\n","    for i in range(0, train_df.shape[0]):\n","        length = len(train_df.iloc[i].sentences)\n","        if length > max_number_of_sentences:\n","            max_number_of_sentences = length\n","    return max_number_of_sentences\n","\n","max_number_of_sentences = find_max_number_of_sentences()\n","max_number_of_sentences\n"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"XzbBwSJUZiwk","executionInfo":{"status":"ok","timestamp":1702370217603,"user_tz":480,"elapsed":209,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["# if the length of data is less than the maximum length, add padding to it\n","def pad(data, max_length):\n","    length_of_data = len(data)\n","    pad_number = max_length - length_of_data\n","    data = data + [np.nan] * pad_number\n","    return data\n"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"LLGzsM7uZiwk","executionInfo":{"status":"ok","timestamp":1702370219766,"user_tz":480,"elapsed":404,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["# combine the features, add padding if necesssary and return the resultant data\n","resultant_data = []\n","def combine_features(item):\n","    length_of_sentence = len(item.sentences)\n","    cosine_similarity = item.cosine_similarity\n","    euclidean = item.euclidean\n","\n","    if length_of_sentence < max_number_of_sentences:\n","        euclidean = pad(euclidean, max_number_of_sentences)\n","        cosine_similarity = pad(cosine_similarity, max_number_of_sentences)\n","\n","    features = euclidean + cosine_similarity + [item.target]\n","    resultant_data.append(features)\n","train_df_copy.apply(combine_features, axis = 1)\n","\n","resultant_data = pd.DataFrame(resultant_data)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"3JkI0Gt2Ziwl","executionInfo":{"status":"ok","timestamp":1702370221693,"user_tz":480,"elapsed":17,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["X = resultant_data.iloc[:,:-1]\n","y = resultant_data.iloc[:,-1]"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"I67bxUAXZiwm","executionInfo":{"status":"ok","timestamp":1702370222995,"user_tz":480,"elapsed":158,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"outputs":[],"source":["# train test split\n","train_x, test_x, train_y, test_y = train_test_split(X, y, train_size=0.8, random_state = 5)"]},{"cell_type":"code","source":["# function to find exact match\n","def exact_match(y_true, y_pred):\n","    non_nan_mask = ~np.isnan(y_true)\n","    em_score = np.array_equal(y_true[non_nan_mask], y_pred[non_nan_mask])\n","    return em_score"],"metadata":{"id":"0VdKfBskbOzw","executionInfo":{"status":"ok","timestamp":1702370225142,"user_tz":480,"elapsed":17,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["def exact_match(y_true, y_pred):\n","    non_nan_mask = ~np.isnan(y_true)\n","    em_score = np.array_equal(y_true[non_nan_mask], y_pred[non_nan_mask])\n","    return 1 if em_score else 0\n","total_instances = len(test_y)"],"metadata":{"id":"BuFY5JH8SlE7","executionInfo":{"status":"ok","timestamp":1702370226352,"user_tz":480,"elapsed":191,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T_6REDbrZiwm","executionInfo":{"status":"ok","timestamp":1702370234459,"user_tz":480,"elapsed":6101,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"6f42d518-fe55-4c34-e45e-737e17706c0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Multinomial Logistic regression Train Accuracy :  0.374\n","Multinomial Logistic regression Test Accuracy :  0.374\n","Multinomial Logistic regression Test F1 Score: 0.22427304569685066\n","Multinomial Logistic regression Exact Match Score: 0.374\n"]}],"source":["from sklearn.impute import SimpleImputer\n","\n","# Create an imputer\n","imputer = SimpleImputer(strategy='mean')\n","\n","# Fit and transform the training data\n","train_x_imputed = imputer.fit_transform(train_x)\n","test_x_imputed = imputer.fit_transform(test_x)\n","\n","mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg')\n","mul_lr.fit(train_x_imputed, train_y)\n","\n","print(\"Multinomial Logistic regression Train Accuracy : \", metrics.accuracy_score(train_y, mul_lr.predict(train_x_imputed)))\n","print(\"Multinomial Logistic regression Test Accuracy : \", metrics.accuracy_score(test_y, mul_lr.predict(test_x_imputed)))\n","\n","test_y_pred = mul_lr.predict(test_x_imputed)\n","\n","# Calculate F1 score for multiclass classification\n","f1 = metrics.f1_score(test_y, test_y_pred, average='weighted')\n","print(\"Multinomial Logistic regression Test F1 Score:\", f1)\n","\n","correct_predictions = sum(exact_match(y_true, y_pred) for y_true, y_pred in zip(test_y.values, test_y_pred))\n","\n","em_score = correct_predictions / total_instances\n","print(\"Multinomial Logistic regression Exact Match Score:\", em_score)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3onNZncZiwv","executionInfo":{"status":"ok","timestamp":1702370241918,"user_tz":480,"elapsed":1061,"user":{"displayName":"Amisha H Somaiya","userId":"16913329026696791247"}},"outputId":"8af421e5-28e1-4546-8ca0-29adbc226e2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest Classifier Train Accuracy :  0.54925\n","Random Forest Classifier Test Accuracy :  0.375\n","Random Forest Classifier F1 Score :  0.30240551997552406\n","Random Forest Classifier Exact Match Score: 0.374\n"]}],"source":["# Random Forest Classifier\n","rf = RandomForestClassifier(min_samples_leaf=8, n_estimators=60)\n","rf.fit(train_x_imputed, train_y)\n","\n","print(\"Random Forest Classifier Train Accuracy : \", metrics.accuracy_score(train_y, rf.predict(train_x_imputed)))\n","print(\"Random Forest Classifier Test Accuracy : \", metrics.accuracy_score(test_y, rf.predict(test_x_imputed)))\n","print(\"Random Forest Classifier F1 Score : \", metrics.f1_score(test_y, rf.predict(test_x_imputed), average='weighted'))\n","correct_predictions = sum(exact_match(y_true, y_pred) for y_true, y_pred in zip(test_y.values, test_y_pred))\n","\n","em_score = correct_predictions / total_instances\n","print(\"Random Forest Classifier Exact Match Score:\", em_score)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[{"file_id":"16eF6sa-Fk10TDEO5e2fzVKjSUtsg9DeX","timestamp":1701737221971}]}},"nbformat":4,"nbformat_minor":0}